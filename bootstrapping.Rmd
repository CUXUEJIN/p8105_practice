---
title: "bootstrapping"
author: "xj2249"
date: "11/14/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

set.seed(1)

```

# generate constant and non-constant error
```{r}
n_samp = 250

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)
```

# see what we get
```{r}
sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "data_source") 

sim_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  facet_grid(~data_source) 
```

# fit linear regression model
```{r}
lm(y ~ x, data = sim_df_const) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

lm(y ~ x, data = sim_df_nonconst) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```
The fact that the error is not constant doesn't affect the point estimate very much, or to say the estimate is very ok. They are very close. 
But the confidence interval will be a problem. Let's see how. 

# bootstrap

## Drawing one bootstrap sample, let's write a function
```{r}
boot_sample = function(df) {
  sample_frac(df, size = 1,  replace = TRUE)
}
# size = 1, so we have keep the same sample size;
# replace = TRUE, so we can get a new sample(you draw one and put it back, and continue next drawing )
```

check it
```{r}
boot_sample(sim_df_nonconst) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm")
# alpha = .5, so darker = sampled more than once
```

## Drawing many bootstrap samples(rerun comes back!)
```{r}
boot_straps = 
  data_frame(
    strap_number = 1:1000,
    strap_sample = rerun(1000, boot_sample(sim_df_nonconst))
  )
```


```{r}
boot_straps %>% 
  filter(strap_number %in% 1:3) %>% 
  unnest(strap_sample) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm", se = FALSE) +
  facet_grid(~strap_number) 
```

## Analyzing bootstrap samples

```{r}
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(y ~ x, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest() %>% 
  group_by(term) %>% 
  summarize(boot_se = sd(estimate),
            boot_mean = mean(estimate))

bootstrap_results %>% 
  knitr::kable(digits = 3)
```

## compare the result (se) with the original sample
```{r}
lm(y ~ x, data = sim_df_nonconst) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```
intercept:  0.099 vs 0.06
 x : 0.071 and 0.106 
 kind of comfused about the "se" here. take some time to think about it. 

# jeff's explanation:
Comparing these to the results of ordinary least squares, the standard error for the intercept is much smaller and the standard error for the intercept is a bit larger. This is reasonable, given the non-constant variance in the data given smaller residuals around zero and larger residuals in the the tails of the x distribution.

it's to say we need to undersatnd not constant variance's effect on the distribution of our estimates. 

For a simple linear regression, we can show the fitted lines for each bootstrap sample to build intuition for these results.
```{r}
boot_straps %>% 
  unnest(strap_sample) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_line(aes(group = strap_number), stat = "smooth", method = "lm", se = FALSE, alpha = .1, color = "blue") +
  geom_point(data = sim_df_nonconst, alpha = .5)
```
In comparison to the standard error bands in our previous plot (which are based on OLS), the *distribution of regression lines* is narrower near x=0
 and wider at the ends of the x distribution.

# Do this in a quicker way!
## use modelr::bootstrap; so that we save the trouble to write a function.
```{r}
boot_straps = 
  sim_df_nonconst %>% 
  modelr::bootstrap(n = 1000)
```

##repeat what we just did 
```{r}
sim_df_nonconst %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(y ~ x, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  group_by(term) %>% 
  summarize(boot_se = sd(estimate))
```

## check the one with constant error variance. just change the df name(fast and essy!) 
```{r}
sim_df_const %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x) ),
         results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  group_by(term) %>% 
  summarize(boot_se = sd(estimate))
```
These results generally agree with the output of the OLS procedure, which is nice.

what does it mean by saying "agree with" ??? 


